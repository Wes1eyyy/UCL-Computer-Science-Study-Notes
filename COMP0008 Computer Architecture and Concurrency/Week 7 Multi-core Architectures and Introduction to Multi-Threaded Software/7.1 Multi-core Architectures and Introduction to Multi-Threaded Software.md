# 📝 Single Process Server: Core Ideas

![[Design 1 single process.png]]

- **Server Task**: Handle many client requests (e.g., computations) via the web.
    
- **Initial Design**:
    
    - One **monolithic**（单体式） server program.
        
    - Runs as a **single process**, typically with **one thread**.
        
- **Problem**:
    
    - All requests processed **sequentially**.
        
    - Only **one CPU core** is used (others idle).
        
    - **Long tasks** block all other requests.
        
    - **Result**: Very **slow** and sometimes **blocked** server.
        
- **Conclusion**:
    
    - Single-threaded servers cannot efficiently handle concurrent requests.
        
    - We must design the server to **use multiple cores** to improve performance.
        

---

# Design 2: Multiple Processes

![[Design 2 multiple processes.png]]

- **Idea**: Create a new **process** for each client connection.
    
- **Each process** has its own code, data, files, stack, and registers.
    
- **OS load balances** processes across cores automatically.
    

---

## Problems

- **High resource consumption**:  
    Each process uses separate memory and CPU → wasteful.
    
- **Expensive communication**:  
    Inter-process communication (IPC) is slow and complex.
    
- **Heavy management overhead**:  
    OS spends too much time managing processes instead of running tasks.
    

---

## Summary

|Pros|Cons|
|:--|:--|
|Full CPU core utilization|Heavy resource usage|
|Simple programming model|Slow IPC and scaling issues|


---

# Design 3: Multiple Threads

![[Design 3 Multiple Threads.png]]

- **Single process**, **one thread per client**.
    
- Threads are **lightweight** and **share most resources** (code, data).
    
- Threads are **minimal scheduling units**: run independently, possibly on different cores.
    
- **Advantage**: saves resources, allows parallelism.
    
- **Problem**:
    
    - Harder to program correctly.
        
    - **Unexpected interactions** with hardware.
        
    - **Shared resource issues** (e.g., data races).
        
    - **Difficult to reason** about parallel execution.

---

### 🧠 Notes: Design 3 is not always best

- Not all servers must be multithreaded.
    
- Design 1 or 2 may be better if app is not CPU-intensive or time-sensitive.
    
- Tradeoff: simplicity vs correctness vs performance.  
    → Pick the easiest design that meets requirements.
    
- Concurrency bugs happen when multiple processes/threads share resources.
    

---

### 🧠 Notes: Multithreading ≠ True Parallelism

- Multithreading support depends on language.
    
- In CPython, **GIL** allows only **one thread** to execute at a time.
    
- For real parallelism in Python, use `multiprocessing` or `concurrent.futures`.
    

---

# Concurrency Abstraction(并发抽象) 

虽然现实中硬件执行是并发的、复杂的，但我们可以抽象成「线程之间的原子动作被**交错执行（interleaving）**」

- Hardware **unpredictably interleaves** actions from all threads.
    
- Each thread = a **totally ordered** sequence of atomic actions.
    
- **Interleaving** = totally ordered sequence mixing actions from different threads.
    
    - Only **one action at a time** is executed.
        
    - Actions from the **same thread** keep their order.
        
- Many possible interleavings → different execution results.
    

---

# Correctness of the Abstraction

- We **model** problems caused by actions from different threads.
    
- **Limitations**:
    
    - **No time modeling**.
        
    - **No hardware detail modeling** (e.g., reordering, caching).
        
- Abstraction is **good enough** for most concurrency reasoning.

---

# Building upon Concurrency Abstraction

- Concurrency abstraction helps solve concurrency problems.
    
- Solutions use **primitives of programming languages**.
    
- Programming languages provide **constructs** to:
    
    - Execute code blocks atomically (critical sections).
        
    - Restrict possible interleavings.
        
- Programming languages define **guarantees** of these constructs, independent of hardware.

---

# Interleaving Example - Minimal Notes

- Threads:
    
    - A = {A1, A2}
        
    - B = {B1}
        
- Rule:
    
    - Actions inside a thread must stay in order (A1 before A2).
        
    - Actions across threads can interleave freely.
        
- Result:
    
    - 3 interleavings: [A1, A2, B1], [A1, B1, A2], [B1, A1, A2].

---

# Interleaving Example (Variant) - Minimal Notes

- Threads:
    
    - A = {A1, A2}
        
    - B = {B1, B2}
        
- Rule:
    
    - Actions inside threads stay ordered.
        
- Result:
    
    - 6 interleavings:
        
        - If A1 first: [A1,A2,B1,B2], [A1,B1,A2,B2], [A1,B1,B2,A2]
            
        - If B1 first: [B1,A1,A2,B2], [B1,A1,B2,A2], [B1,B2,A1,A2]
            
- Insight:
    
    - Adding 1 more action → doubles interleavings!

---

# Interleaving Formula - Minimal Notes

- Threads:
    
    - A has X actions
        
    - B has Y actions
        
- Total interleavings = $$(X+Y)! / (X! × Y!)$$
    
- Idea:
    
    - Place all actions in sequence, keeping thread order.
        
    - "Stars and bars" method.
---

# Three Threads - Minimal Notes

- Threads:
    
    - A = {A1}
        
    - B = {B1}
        
    - C = {C1}
        
- Total actions = 3
    
- Total interleavings = 3! = 6
    
- Enumeration:
    
    - A1 first: [A1, B1, C1], [A1, C1, B1]
        
    - B1 first: [B1, A1, C1], [B1, C1, A1]
        
    - C1 first: [C1, B1, A1], [C1, A1, B1]
        

---
# Three Threads (Variant) - Minimal Notes

- Threads:
    
    - A = {A1, A2}
        
    - B = {B1}
        
    - C = {C1}
        
- Total actions = 4
    
- Rules:
    
    - Actions in the same thread must stay ordered (A1 before A2).
        
- Total interleavings = 12
    
- Enumeration:
    
    - A1 first: [A1,A2,B1,C1], [A1,A2,C1,B1], [A1,B1,A2,C1], [A1,B1,C1,A2], [A1,C1,A2,B1], [A1,C1,B1,A2]
        
    - B1 first: [B1,A1,A2,C1], [B1,A1,C1,A2], [B1,C1,A1,A2]
        
    - C1 first: [C1,B1,A1,A2], [C1,A1,B1,A2], [C1,A1,A2,B1]
        

---

## Simple program example

- **Question**: What are possible final values of `x` if:
    
    - T1: `{x=5; x=2*x}`
        
    - T2: `{x=x+2}`
        
- **Interleaving assuming atomic instructions**:
    
    1. `x=5; x=2*x; x=x+2` → x=12
        
    2. `x=5; x=x+2; x=2*x` → x=14
        
    3. `x=x+2; x=5; x=2*x` → x=10
        
- **But are operations atomic?**
    
    - `x=2*x` = read `x` → compute → write result
        
    - `x=x+2` = read `x` → compute → write result
        
    - Can split into smaller actions (not atomic).
        
- **Thus more interleavings possible!** 4. `s=0; T1: x=s+2` → x=2 5. `s=0; x=5; x=s+2; x=2*x` → x=4 6. `x=5; s=5; ...; x=s+2` → x=7
    
- **Key Point**:
    
    - Non-atomic instructions increase the number of possible outcomes.
        
    - Careful when assuming operations are indivisible!
        

---
# Lessons Learned:
- Combinatorial explosion: many interleavings, grows fast with more threads/actions.
- Real concurrent programs = many threads and many actions.
- Static analysis is hard → need good design from the start.
- Explosion causes unpredictability and non-determinism.
- Bugs are hard to find and can stay latent for a long time.


---

### 总结：

首先，总结今天课上学到的重要教训：

1. **组合爆炸（Combinatorial explosion）**
    
    - 并发程序中，线程的交错组合数量随线程数和操作数迅速增长（比如只有两条线程时，就是二项式系数）。
        
    - 线程越多、每个线程的操作越多，组合就越多，导致几乎无法穷举。
        
2. **现实的并发程序（Real concurrent programs）**
    
    - 实际程序通常有**很多线程**，每个线程又有**很多操作**，组合规模巨大。
        
3. **静态分析很困难（Hard to analyze statically）**
    
    - 用手工分析或形式工具去推导所有可能情况在实际中不可行。
        
    - **结论：必须一开始就设计好！**（比如用同步机制和正确的模式）
        

4. **不可预测性与非确定性（Unpredictability & Non-determinism）**
    
    - 程序可能有许多不同的执行结果，而且随着规模增大，结果种类难以穷举。
        
    - 有些交错更容易发生，有些则极少发生：
        
        - 导致**并发bug难以测试发现**。
            
        - 少见的交错可能潜藏着**潜在bug（latent bugs）**，只有在极少的情况下才触发。
            

---
