
# üß† From C to MIPS Instructions

## üßæ Given C code
```c
a = b + e;
c = b + f;
````

## üìç Assumptions

- All variables are stored in memory.
    
- Memory is addressable using offsets from `$t0`.
    

|Variable|Address|
|---|---|
|`b`|`0($t0)`|
|`e`|`4($t0)`|
|`f`|`8($t0)`|
|`a`|`12($t0)`|
|`c`|`16($t0)`|

---

## üîÅ Step-by-step MIPS Translation

### 1Ô∏è‚É£ `a = b + e;`

```mips
lw $t1, 0($t0)        # $t1 = b
lw $t2, 4($t0)        # $t2 = e
add $t3, $t1, $t2     # $t3 = b + e
sw $t3, 12($t0)       # store result to a
```

### 2Ô∏è‚É£ `c = b + f;`

```mips
lw $t4, 8($t0)        # $t4 = f
add $t5, $t1, $t4     # $t5 = b + f (reuse $t1)
sw $t5, 16($t0)       # store result to c
```

---

## ‚úÖ Summary

- All arithmetic must happen **in registers**.
    
- Memory access only via `lw` (load) and `sw` (store).
    
- Use registers to hold intermediate results.
    

---

## üí° Memory-Register Workflow

> **Load ‚Üí Compute ‚Üí Store**

```text
lw ‚Üí add/sub/... ‚Üí sw
```

---

## üõë MIPS Pipeline: Stalling

### ‚ùì Problem

When executing dependent instructions in a pipeline:

```mips
lw   $t1, 0($t0)      # Load b into $t1  
lw   $t2, 4($t0)      # Load e into $t2  
add  $t3, $t1, $t2    # a = b + e
```

The `add` instruction **depends on** the results of the two `lw` instructions.

---

### ‚ö†Ô∏è Data Hazard

- `$t1` and `$t2` are **not ready** (not yet written back) when `add` reaches the decode stage.
    
- This creates a **RAW (Read After Write)** hazard.
    

---

### üîÑ Solution: Stalling

To avoid incorrect results, we **insert NOPs** between dependent instructions:

```mips
lw   $t1, 0($t0)  
lw   $t2, 4($t0)  
nop  
add  $t3, $t1, $t2  
```

This gives enough time for `$t1` and `$t2` to be written back before they are read by `add`.

---

### üß± 5 Pipeline Stages (Classic MIPS)

|Stage|Name|Description|
|---|---|---|
|**IF**|Instruction Fetch|Fetch instruction from instruction memory (IM).|
|**ID**|Instruction Decode|Decode instruction, read register file (RF) ‚Äî e.g., get `$t0`.|
|**EX**|Execute|Use ALU to compute address: `0 + $t0`.|
|**MEM**|Memory Access|Access data memory (DM) and read word.|
|**WB**|Write Back|Write result back to register `$t1`.|

---

### ‚úÖ Summary

> **Stalling** introduces **pipeline delays** to resolve data hazards and ensure correctness, at the cost of performance.


---

## üßÆ MIPS Pipelining & Cache Summary

### üß† Instruction Reordering

- **Goal**: Reduce stalls (e.g., `nop`) by reordering independent instructions.
    
- **Example**:
    
    ```mips
    lw   $t1, 0($t0)
    lw   $t2, 4($t0)
    # nop removed here
    lw   $t4, 8($t0)       # moved up
    add  $t3, $t1, $t2
    sw   $t3, 12($t0)
    # nop removed here
    add  $t5, $t1, $t4
    sw   $t5, 16($t0)
    ```
    

---

### ‚è±Ô∏è Is pipelining fast?

- **Pipelining increases throughput**, not individual instruction speed.
    
- The **main bottleneck** becomes **memory access** (especially for `lw` / `sw`).
    
- Accessing main memory takes `O(100)` clock cycles.
    

---

### ‚öôÔ∏è Cache: Solving the Memory Bottleneck

- **Cache** sits between processor and main memory.
    
- **Fast** (~1 clock cycle), but **small and expensive**.
    
- Cache holds a **subset of main memory**.
    

---

### üß≠ Why Cache Works: Locality

- **Temporal locality**: recently used data is likely to be reused soon.
    
- **Spatial locality**: data near recently accessed locations is likely to be used.
    

---

### üí• Cache in Action

#### When executing `lw`:

1. **Check cache first**
    
    - ‚úÖ `cache hit` ‚Üí return data directly.
        
    - ‚ùå `cache miss` ‚Üí load from main memory and update cache.
        
2. **Cache updates**:
    
    - Missed data ‚Üí for **temporal locality**.
        
    - Nearby data ‚Üí for **spatial locality**.
        

---
# üß† Cache Internals (Set-Associative)

![[Cache Internals.png]]

## Structure
- Cache is divided into multiple **sets**.
- Each **set** maps to specific blocks of main memory.
- Each set contains multiple **ways** (e.g. 2-way cache).

## Components per way:
- **V (Valid bit)**: whether data is valid
- **Tag**: high bits of address, used to match
- **Data**: actual cached data

## Address Breakdown
For example: `lw 1100001` (7-bit address)
- **Tag** = `110`
- **Set Index** = `00` (select Set 0)
- **Offset** = `01` (byte inside block)

## Cache Access Steps
1. Use **set index** to select the set.
2. Compare **tag** with each way's tag in that set.
3. If **valid bit == 1** and **tag matches**, ‚Üí **Cache Hit**.
4. Else ‚Üí **Cache Miss**, load from memory.

## Logic Circuit Overview
- Uses comparators for each way.
- Uses **MUX** to select the correct data.
- Outputs data if hit, otherwise loads from memory.


---

## üß† Cache in Practice (MIPS Systems)

### üîß Cache Dimensioning

- Key parameters:
    
    - **Number of sets**
        
    - **Number of blocks per set** (a.k.a. **ways**)
        
    - **Block size** (how many bytes per block)
        
- These parameters determine the size and associativity of the cache.
    

---

### ‚ôªÔ∏è Replacement Strategy

- When a new block must be loaded into a full cache set:
    
    - **Least Recently Used (LRU)** ‚Äì replace the block that hasn‚Äôt been accessed for the longest time.
        
    - **Random** ‚Äì choose any block randomly to evict.
        

---

### ‚úçÔ∏è Writing Strategy

- When a value is written to the cache:
    
    - **Write-through** ‚Äì write the data to both cache and memory immediately.
        
    - **Write-back** ‚Äì only write to memory when the block is evicted (requires a dirty bit).
        

---

### üìä Number of Cache Levels

- Typically multiple levels of cache:
    
    - **L1 cache** ‚Äì smallest, fastest, closest to the CPU.
        
    - **L2 / L3 caches** ‚Äì larger, slower, shared across cores.
        
- More levels = better performance, but also more complexity.
    

---

## üß† Cache Coherence in Multi-Core Systems

### Scenario

- 4 processors with private caches.
    
- Shared cache below private caches.
    
- Shared main memory at the bottom.
    

### Events:

- **t0**: Main memory location `X` holds `1`.
    
- **t1**: Processor 1 loads and caches `X = 1`.
    
- **t2**: Processor 2 also caches `X = 1`.
    

Now, copies of `X` exist in:

- Main memory
    
- Shared cache
    
- Processor 1's cache
    
- Processor 2's cache
    

---

### ‚ö†Ô∏è Cache Incoherence

- **t3**: Processor 1 modifies `X = 0` in its private cache.
    
- But all other copies still read `X = 1`.
    

This inconsistency between caches is called **cache incoherence**.

---

## ‚úÖ Solution: Cache Coherence Protocols

To resolve inconsistencies:

### Common Protocols:

- **MSI**: Modified, Shared, Invalid
    
- **MESI**: Modified, Exclusive, Shared, Invalid
    
- **MOESI**: Adds Owned state
    

### What they do:

- Use **signals/broadcasts** to inform other caches when a processor **reads/writes** a shared memory block.
    
- Enforce consistent views across all caches.
    

---